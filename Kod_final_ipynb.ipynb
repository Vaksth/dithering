{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(load_path, save_img_path, save_data_path, image_number):\n",
    "\n",
    "    ######################################\n",
    "    #########        BEGIN       #########\n",
    "    ######### K-means clustering #########\n",
    "    ######################################\n",
    "\n",
    "    import os\n",
    "    from imageio import imread\n",
    "    import numpy as np\n",
    "    from skimage.color import rgb2lab, lab2rgb\n",
    "    from skimage.transform import rescale\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "\n",
    "    image_raw = imread(load_path)\n",
    "\n",
    "    image_width = 400\n",
    "    image = rescale(image_raw, image_width/image_raw.shape[0], mode='reflect', channel_axis=2, anti_aliasing=True)\n",
    "    shape = image.shape\n",
    "\n",
    "\n",
    "    X = rgb2lab(image).reshape(-1, 3)\n",
    "\n",
    "    def cluster_assignments(X, Y):\n",
    "        return np.argmin(euclidean_distances(X,Y), axis=1)\n",
    "\n",
    "    K = 32\n",
    "    centers = np.array([X.mean(0) + (np.random.randn(3)/10) for _ in range(K)])\n",
    "    y_kmeans = cluster_assignments(X, centers)\n",
    "\n",
    "    maxreps = 5\n",
    "    threshold = 1\n",
    "\n",
    "\n",
    "    for b in range(maxreps):\n",
    "        prev_centers = np.copy(centers)\n",
    "\n",
    "        # assign each point to the closest center\n",
    "        y_kmeans = cluster_assignments(X, centers)\n",
    "\n",
    "        # move the centers to the mean of their assigned points (if any)\n",
    "        for i, c in enumerate(centers):\n",
    "            points = X[y_kmeans == i]\n",
    "            if len(points):\n",
    "                centers[i] = points.mean(0)\n",
    "        \n",
    "        #center_movement = np.mean(np.linalg.norm(centers - prev_centers, axis=1))\n",
    "        max_distance = np.max(np.linalg.norm(centers - prev_centers, axis=1))\n",
    "\n",
    "        if max_distance < threshold:\n",
    "            print(f\"\\n\\nCenter movement: {round(max_distance,3)}. Convergence achieved within\", b+1, \"iterations.\\n\\n\")\n",
    "            break\n",
    "        elif b+1 == maxreps:\n",
    "            print(f\"\\n\\nCenter movement: {round(max_distance,3)}. Maximum repetitions reached within\", b+1, \"iterations.\\n\\n\")\n",
    "            break\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #########         END        #########\n",
    "    ######### K-means clustering #########\n",
    "    ######################################\n",
    "\n",
    "\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    def find_closest_centroid_color2(oldpixel, palette):\n",
    "        distances = cdist([oldpixel], palette).flatten()\n",
    "        closest_index = np.argmin(distances)\n",
    "        return closest_index\n",
    "\n",
    "\n",
    "\n",
    "    clustered_image = lab2rgb(centers[y_kmeans,:].reshape(shape[0], shape[1], 3))\n",
    "\n",
    "    # Centroid colors\n",
    "    #lab2rgb retrieves the rgb color in the point of the centroid given in \"centers\".\n",
    "    #(standardized in \"centers\", therefore multiplied by 255 = RGB\n",
    "    palette = np.uint8(lab2rgb(centers)*255)\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #########        BEGIN       #########\n",
    "    ######### Grayscale function #########\n",
    "    ######################################\n",
    "\n",
    "    def grayscale(image):\n",
    "        pil_img = Image.fromarray(np.uint8(image))\n",
    "        gray_img = pil_img.convert('L')\n",
    "        gray_np = np.array(gray_img)\n",
    "        grayscale_img = np.stack((gray_np, gray_np, gray_np), axis=-1)\n",
    "        return grayscale_img\n",
    "\n",
    "    ######################################\n",
    "    #########         END        #########\n",
    "    ######### Grayscale function #########\n",
    "    ######################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #########        BEGIN       #########\n",
    "    #########      Dithering     #########\n",
    "    ######################################\n",
    "\n",
    "\n",
    "    img = image.astype(np.float64)*255  # original image (rescaled)\n",
    "\n",
    "    original_image = Image.fromarray(np.uint8(img))\n",
    "    original_image_array = np.uint8(img)\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    for y in range(0, width):\n",
    "        for x in range(0, height):\n",
    "            oldpixel = np.copy(img[x, y])\n",
    "            newpixel = palette[find_closest_centroid_color2(oldpixel, palette)]\n",
    "            img[x, y] = newpixel\n",
    "            quant_err = oldpixel - newpixel\n",
    "\n",
    "\n",
    "            if x < height - 1: \n",
    "                img[x + 1, y    ] += quant_err * 7/16\n",
    "            if y < width - 1: \n",
    "                img[x - 1, y + 1] += quant_err * 3/16\n",
    "            if y < width - 1: \n",
    "                img[x    , y + 1] += quant_err * 5/16\n",
    "            if y < width - 1 and x < height - 1: \n",
    "                img[x + 1, y + 1] += quant_err * 1/16\n",
    "\n",
    "\n",
    "    # Save dithered image\n",
    "    dithered_img = Image.fromarray(np.uint8(img))\n",
    "    dithered_img_array = np.uint8(img)\n",
    "    original_image.save(f'{save_img_path}/original_img{image_number}.bmp', format='BMP')\n",
    "    dithered_img.save(f'{save_img_path}/dithered_img{image_number}.bmp', format='BMP')\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #########         END        #########\n",
    "    #########      Dithering     #########\n",
    "    ######################################\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #########        BEGIN       #########\n",
    "    #########      Statistik     #########\n",
    "    ######################################\n",
    "\n",
    "    #####            #####\n",
    "    ##### -- SSIM -- #####\n",
    "\n",
    "\n",
    "    ### Dithering compression ###\n",
    "\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    from skimage import color\n",
    "\n",
    "    # Convert to grayscale and cast back to uint8\n",
    "    original_array = np.uint8(grayscale(original_image_array))\n",
    "    dithered_array = np.uint8(grayscale(dithered_img_array))\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim1, _ = ssim(original_array, dithered_array, full=True, channel_axis=2)\n",
    "\n",
    "    print(f\"SSIM Index: {round(ssim1, 3)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### JPEG compression ###\n",
    "\n",
    "    # Load the images using Pillow\n",
    "    uncompressed_img = Image.fromarray(np.uint8(image*255))\n",
    "    uncompressed_img.save(f'{save_img_path}/jpg_img{image_number}.jpg', \"JPEG\", optimize = True, quality = 1) \n",
    "\n",
    "    compressed_img = Image.open(f'{save_img_path}/jpg_img{image_number}.jpg')\n",
    "    \n",
    "    # Convert Pillow images to NumPy arrays\n",
    "    original_array = np.uint8(grayscale(original_image_array))\n",
    "    compressed_array = np.uint8(grayscale(np.array(compressed_img)))\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim2, _ = ssim(original_array, compressed_array, full=True, channel_axis=2)\n",
    "\n",
    "    print(f\"SSIM Index: {round(ssim2, 3)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####           #####\n",
    "    ##### -- MSE -- #####\n",
    "    from skimage.metrics import mean_squared_error\n",
    "\n",
    "    mse1 = mean_squared_error(original_image_array, dithered_img_array)\n",
    "\n",
    "    mse2 = mean_squared_error(original_image_array, np.array(compressed_img))\n",
    "\n",
    "    print(\"Original / dithered\")\n",
    "    print(\"MSE:\", round(mse1,2))\n",
    "\n",
    "    print(\"\\nOriginal / JPG-compressed\")\n",
    "    print(\"MSE:\", round(mse2,2))\n",
    "\n",
    "    print(\"\\n\\nControl with same image: \\n\", mean_squared_error(original_image_array, original_image_array))\n",
    "\n",
    "\n",
    "    #####            #####\n",
    "    ##### -- PSNR -- #####\n",
    "\n",
    "    from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "    psnr1 = peak_signal_noise_ratio(original_image_array, dithered_img_array)\n",
    "    psnr2 = peak_signal_noise_ratio(original_image_array, np.array(compressed_img))\n",
    "\n",
    "\n",
    "    print(\"Original / dithered\")\n",
    "    print(f\"PSNR: {round(psnr1,2)} dB\")\n",
    "\n",
    "    print(\"\\nOriginal / JPG-compressed\")\n",
    "    print(f\"PSNR: {round(psnr2, 2)} dB\")\n",
    "\n",
    "    print(\"\\n\\nControl with same image: \\n\",peak_signal_noise_ratio(original_image_array, original_image_array))\n",
    "\n",
    "\n",
    "    #####             #####\n",
    "    ##### -- LPIPS -- #####\n",
    "\n",
    "\n",
    "    ## Dithered ##\n",
    "    from piq import LPIPS\n",
    "    from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    original_tensor = to_tensor(original_image_array).unsqueeze(0)\n",
    "    dithered_tensor = to_tensor(dithered_img_array).unsqueeze(0)\n",
    "\n",
    "    # Calculate LPIPS\n",
    "    lpips1 = LPIPS()(original_tensor, dithered_tensor)\n",
    "    print(f\"LPIPS Loss: {round(lpips1.item(), 3)}\")\n",
    "\n",
    "\n",
    "\n",
    "    ## JPEG ##\n",
    "    from piq import LPIPS\n",
    "    from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    original_tensor = to_tensor(original_image_array).unsqueeze(0)\n",
    "    dithered_tensor = to_tensor(dithered_img_array).unsqueeze(0)\n",
    "\n",
    "    # Calculate LPIPS\n",
    "    lpips2 = LPIPS()(original_tensor, dithered_tensor)\n",
    "    print(f\"LPIPS Loss: {round(lpips2.item(), 3)}\")\n",
    "\n",
    "    \n",
    "\n",
    "    ### Save data in a .txt file\n",
    "    ssim1, ssim2, mse1, mse2, psnr1, psnr2, lpips1, lpips2 = (\n",
    "        round(ssim1, 3), round(ssim2, 3), round(mse1, 3), round(mse2, 3),\n",
    "        round(psnr1, 3), round(psnr2, 3), round(lpips1.item(), 3), round(lpips2.item(), 3)\n",
    "    )\n",
    "    with open(save_data_path, \"a\") as file:\n",
    "        file.write(f\"{ssim1};{ssim2};{mse1};{mse2};{psnr1};{psnr2};{lpips1};{lpips2}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files(load_path):\n",
    "    files = [f for f in os.listdir(load_path) if os.path.isfile(os.path.join(load_path, f))]\n",
    "    num_files = len(files)\n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_16540\\1538109023.py:17: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image_raw = imread(load_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Center movement: 2.018. Maximum repetitions reached within 5 iterations.\n",
      "\n",
      "\n",
      "SSIM Index: 0.699\n",
      "SSIM Index: 0.55\n",
      "Original / dithered\n",
      "MSE: 222.04\n",
      "\n",
      "Original / JPG-compressed\n",
      "MSE: 416.39\n",
      "\n",
      "\n",
      "Control with same image: \n",
      " 0.0\n",
      "Original / dithered\n",
      "PSNR: 24.67 dB\n",
      "\n",
      "Original / JPG-compressed\n",
      "PSNR: 21.94 dB\n",
      "\n",
      "\n",
      "Control with same image: \n",
      " inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\3week24_venv\\Lib\\site-packages\\skimage\\metrics\\simple_metrics.py:163: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 10 * np.log10((data_range ** 2) / err)\n",
      "c:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\3week24_venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\3week24_venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPIPS Loss: 0.494\n",
      "LPIPS Loss: 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_16540\\1538109023.py:17: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image_raw = imread(load_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Center movement: 4.85. Maximum repetitions reached within 5 iterations.\n",
      "\n",
      "\n",
      "SSIM Index: 0.731\n",
      "SSIM Index: 0.575\n",
      "Original / dithered\n",
      "MSE: 204.83\n",
      "\n",
      "Original / JPG-compressed\n",
      "MSE: 337.41\n",
      "\n",
      "\n",
      "Control with same image: \n",
      " 0.0\n",
      "Original / dithered\n",
      "PSNR: 25.02 dB\n",
      "\n",
      "Original / JPG-compressed\n",
      "PSNR: 22.85 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\3week24_venv\\Lib\\site-packages\\skimage\\metrics\\simple_metrics.py:163: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 10 * np.log10((data_range ** 2) / err)\n",
      "c:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\3week24_venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\3week24_venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Control with same image: \n",
      " inf\n",
      "LPIPS Loss: 0.436\n",
      "LPIPS Loss: 0.436\n"
     ]
    }
   ],
   "source": [
    "uncompressed_path = f'C:/Users/Lenovo/Desktop/DTU/1. semester/Introduktion til Intelligente Systemer/Eksamen/3-ugers projekt/data/uncompressed/'\n",
    "\n",
    "save_data_path = r'C:\\Users\\Lenovo\\Desktop\\DTU\\1. semester\\Introduktion til Intelligente Systemer\\Eksamen\\3-ugers projekt\\data\\data.txt'\n",
    "#range(count_files(load_path))\n",
    "for i in range(2):\n",
    "    uncompressed_images = [f for f in os.listdir(uncompressed_path) if os.path.isfile(os.path.join(uncompressed_path, f))]\n",
    "    load_path = f'C:/Users/Lenovo/Desktop/DTU/1. semester/Introduktion til Intelligente Systemer/Eksamen/3-ugers projekt/data/uncompressed/{uncompressed_images[i]}'\n",
    "    save_img_path = f'C:/Users/Lenovo/Desktop/DTU/1. semester/Introduktion til Intelligente Systemer/Eksamen/3-ugers projekt/data/compressed/img{i}'\n",
    "    folder_path = os.makedirs(save_img_path, exist_ok=True)\n",
    "    compress(load_path, save_img_path, save_data_path, i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3week24_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
